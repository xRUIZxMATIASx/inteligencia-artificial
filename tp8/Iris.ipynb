{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = datasets.load_iris(as_frame=True, )\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de iteraciones: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = Perceptron(\n",
    "             # random_state=42,\n",
    "              max_iter=10,\n",
    "              tol=0.001,\n",
    "              #verbose = True\n",
    "              )\n",
    "p.fit(X_train, y_train)\n",
    "print(\"Cantidad de iteraciones: \" +str(p.n_iter_))\n",
    "disp = metrics.plot_confusion_matrix(p, X_test, y_test,cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron multicapa\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Christoph_Oberndorfer/publication/325115915/figure/fig9/AS:625915105132546@1526241198559/Overview-of-the-most-common-activation-functions-identity-binary-step-ReLU-logistic_W640.jpg\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.10256504\n",
      "Iteration 2, loss = 1.10099865\n",
      "Iteration 3, loss = 1.09979523\n",
      "Iteration 4, loss = 1.09889268\n",
      "Iteration 5, loss = 1.09819535\n",
      "Iteration 6, loss = 1.09759239\n",
      "Iteration 7, loss = 1.09699209\n",
      "Iteration 8, loss = 1.09634334\n",
      "Iteration 9, loss = 1.09563355\n",
      "Iteration 10, loss = 1.09487450\n",
      "Iteration 11, loss = 1.09408811\n",
      "Iteration 12, loss = 1.09329660\n",
      "Iteration 13, loss = 1.09251686\n",
      "Iteration 14, loss = 1.09175759\n",
      "Iteration 15, loss = 1.09101856\n",
      "Iteration 16, loss = 1.09029199\n",
      "Iteration 17, loss = 1.08956550\n",
      "Iteration 18, loss = 1.08882608\n",
      "Iteration 19, loss = 1.08806358\n",
      "Iteration 20, loss = 1.08727263\n",
      "Iteration 21, loss = 1.08645266\n",
      "Iteration 22, loss = 1.08560648\n",
      "Iteration 23, loss = 1.08473828\n",
      "Iteration 24, loss = 1.08385176\n",
      "Iteration 25, loss = 1.08294873\n",
      "Iteration 26, loss = 1.08202849\n",
      "Iteration 27, loss = 1.08108803\n",
      "Iteration 28, loss = 1.08012275\n",
      "Iteration 29, loss = 1.07912754\n",
      "Iteration 30, loss = 1.07809782\n",
      "Iteration 31, loss = 1.07703024\n",
      "Iteration 32, loss = 1.07592278\n",
      "Iteration 33, loss = 1.07477455\n",
      "Iteration 34, loss = 1.07358520\n",
      "Iteration 35, loss = 1.07235428\n",
      "Iteration 36, loss = 1.07108077\n",
      "Iteration 37, loss = 1.06976282\n",
      "Iteration 38, loss = 1.06839783\n",
      "Iteration 39, loss = 1.06698265\n",
      "Iteration 40, loss = 1.06551399\n",
      "Iteration 41, loss = 1.06398875\n",
      "Iteration 42, loss = 1.06240422\n",
      "Iteration 43, loss = 1.06075812\n",
      "Iteration 44, loss = 1.05904850\n",
      "Iteration 45, loss = 1.05727355\n",
      "Iteration 46, loss = 1.05543139\n",
      "Iteration 47, loss = 1.05351993\n",
      "Iteration 48, loss = 1.05153684\n",
      "Iteration 49, loss = 1.04947956\n",
      "Iteration 50, loss = 1.04734537\n",
      "Iteration 51, loss = 1.04513157\n",
      "Iteration 52, loss = 1.04283552\n",
      "Iteration 53, loss = 1.04045471\n",
      "Iteration 54, loss = 1.03798673\n",
      "Iteration 55, loss = 1.03542929\n",
      "Iteration 56, loss = 1.03278011\n",
      "Iteration 57, loss = 1.03003691\n",
      "Iteration 58, loss = 1.02719735\n",
      "Iteration 59, loss = 1.02425904\n",
      "Iteration 60, loss = 1.02121957\n",
      "Iteration 61, loss = 1.01807652\n",
      "Iteration 62, loss = 1.01482753\n",
      "Iteration 63, loss = 1.01147029\n",
      "Iteration 64, loss = 1.00800257\n",
      "Iteration 65, loss = 1.00442224\n",
      "Iteration 66, loss = 1.00072721\n",
      "Iteration 67, loss = 0.99691548\n",
      "Iteration 68, loss = 0.99298511\n",
      "Iteration 69, loss = 0.98893422\n",
      "Iteration 70, loss = 0.98476098\n",
      "Iteration 71, loss = 0.98046367\n",
      "Iteration 72, loss = 0.97604068\n",
      "Iteration 73, loss = 0.97149050\n",
      "Iteration 74, loss = 0.96681183\n",
      "Iteration 75, loss = 0.96200351\n",
      "Iteration 76, loss = 0.95706459\n",
      "Iteration 77, loss = 0.95199434\n",
      "Iteration 78, loss = 0.94679227\n",
      "Iteration 79, loss = 0.94145813\n",
      "Iteration 80, loss = 0.93599194\n",
      "Iteration 81, loss = 0.93039400\n",
      "Iteration 82, loss = 0.92466491\n",
      "Iteration 83, loss = 0.91880561\n",
      "Iteration 84, loss = 0.91281735\n",
      "Iteration 85, loss = 0.90670175\n",
      "Iteration 86, loss = 0.90046080\n",
      "Iteration 87, loss = 0.89409687\n",
      "Iteration 88, loss = 0.88761273\n",
      "Iteration 89, loss = 0.88101155\n",
      "Iteration 90, loss = 0.87429691\n",
      "Iteration 91, loss = 0.86747283\n",
      "Iteration 92, loss = 0.86054372\n",
      "Iteration 93, loss = 0.85351442\n",
      "Iteration 94, loss = 0.84639019\n",
      "Iteration 95, loss = 0.83917667\n",
      "Iteration 96, loss = 0.83187991\n",
      "Iteration 97, loss = 0.82450633\n",
      "Iteration 98, loss = 0.81706270\n",
      "Iteration 99, loss = 0.80955611\n",
      "Iteration 100, loss = 0.80199398\n",
      "Iteration 101, loss = 0.79438396\n",
      "Iteration 102, loss = 0.78673398\n",
      "Iteration 103, loss = 0.77905215\n",
      "Iteration 104, loss = 0.77134676\n",
      "Iteration 105, loss = 0.76362620\n",
      "Iteration 106, loss = 0.75589899\n",
      "Iteration 107, loss = 0.74817364\n",
      "Iteration 108, loss = 0.74045870\n",
      "Iteration 109, loss = 0.73276265\n",
      "Iteration 110, loss = 0.72509388\n",
      "Iteration 111, loss = 0.71746065\n",
      "Iteration 112, loss = 0.70987103\n",
      "Iteration 113, loss = 0.70233287\n",
      "Iteration 114, loss = 0.69485375\n",
      "Iteration 115, loss = 0.68744096\n",
      "Iteration 116, loss = 0.68010142\n",
      "Iteration 117, loss = 0.67284170\n",
      "Iteration 118, loss = 0.66566799\n",
      "Iteration 119, loss = 0.65858601\n",
      "Iteration 120, loss = 0.65160107\n",
      "Iteration 121, loss = 0.64471801\n",
      "Iteration 122, loss = 0.63794118\n",
      "Iteration 123, loss = 0.63127446\n",
      "Iteration 124, loss = 0.62472123\n",
      "Iteration 125, loss = 0.61828439\n",
      "Iteration 126, loss = 0.61196635\n",
      "Iteration 127, loss = 0.60576903\n",
      "Iteration 128, loss = 0.59969389\n",
      "Iteration 129, loss = 0.59374192\n",
      "Iteration 130, loss = 0.58791368\n",
      "Iteration 131, loss = 0.58220928\n",
      "Iteration 132, loss = 0.57662847\n",
      "Iteration 133, loss = 0.57117057\n",
      "Iteration 134, loss = 0.56583457\n",
      "Iteration 135, loss = 0.56061913\n",
      "Iteration 136, loss = 0.55552259\n",
      "Iteration 137, loss = 0.55054302\n",
      "Iteration 138, loss = 0.54567825\n",
      "Iteration 139, loss = 0.54092588\n",
      "Iteration 140, loss = 0.53628329\n",
      "Iteration 141, loss = 0.53174773\n",
      "Iteration 142, loss = 0.52731629\n",
      "Iteration 143, loss = 0.52298595\n",
      "Iteration 144, loss = 0.51875357\n",
      "Iteration 145, loss = 0.51461597\n",
      "Iteration 146, loss = 0.51056990\n",
      "Iteration 147, loss = 0.50661211\n",
      "Iteration 148, loss = 0.50273930\n",
      "Iteration 149, loss = 0.49894819\n",
      "Iteration 150, loss = 0.49523554\n",
      "Iteration 151, loss = 0.49159812\n",
      "Iteration 152, loss = 0.48803275\n",
      "Iteration 153, loss = 0.48453632\n",
      "Iteration 154, loss = 0.48110576\n",
      "Iteration 155, loss = 0.47773810\n",
      "Iteration 156, loss = 0.47443044\n",
      "Iteration 157, loss = 0.47117995\n",
      "Iteration 158, loss = 0.46798391\n",
      "Iteration 159, loss = 0.46483967\n",
      "Iteration 160, loss = 0.46174471\n",
      "Iteration 161, loss = 0.45869655\n",
      "Iteration 162, loss = 0.45569285\n",
      "Iteration 163, loss = 0.45273135\n",
      "Iteration 164, loss = 0.44980988\n",
      "Iteration 165, loss = 0.44692637\n",
      "Iteration 166, loss = 0.44407884\n",
      "Iteration 167, loss = 0.44126541\n",
      "Iteration 168, loss = 0.43848427\n",
      "Iteration 169, loss = 0.43573371\n",
      "Iteration 170, loss = 0.43301210\n",
      "Iteration 171, loss = 0.43031789\n",
      "Iteration 172, loss = 0.42764962\n",
      "Iteration 173, loss = 0.42500589\n",
      "Iteration 174, loss = 0.42238539\n",
      "Iteration 175, loss = 0.41978686\n",
      "Iteration 176, loss = 0.41720914\n",
      "Iteration 177, loss = 0.41465111\n",
      "Iteration 178, loss = 0.41211173\n",
      "Iteration 179, loss = 0.40959000\n",
      "Iteration 180, loss = 0.40708501\n",
      "Iteration 181, loss = 0.40459587\n",
      "Iteration 182, loss = 0.40212178\n",
      "Iteration 183, loss = 0.39966197\n",
      "Iteration 184, loss = 0.39721573\n",
      "Iteration 185, loss = 0.39478239\n",
      "Iteration 186, loss = 0.39236132\n",
      "Iteration 187, loss = 0.38995196\n",
      "Iteration 188, loss = 0.38755377\n",
      "Iteration 189, loss = 0.38516625\n",
      "Iteration 190, loss = 0.38278895\n",
      "Iteration 191, loss = 0.38042145\n",
      "Iteration 192, loss = 0.37806337\n",
      "Iteration 193, loss = 0.37571436\n",
      "Iteration 194, loss = 0.37337409\n",
      "Iteration 195, loss = 0.37104229\n",
      "Iteration 196, loss = 0.36871870\n",
      "Iteration 197, loss = 0.36640309\n",
      "Iteration 198, loss = 0.36409525\n",
      "Iteration 199, loss = 0.36179502\n",
      "Iteration 200, loss = 0.35950225\n",
      "Iteration 201, loss = 0.35721679\n",
      "Iteration 202, loss = 0.35493856\n",
      "Iteration 203, loss = 0.35266746\n",
      "Iteration 204, loss = 0.35040343\n",
      "Iteration 205, loss = 0.34814642\n",
      "Iteration 206, loss = 0.34589642\n",
      "Iteration 207, loss = 0.34365340\n",
      "Iteration 208, loss = 0.34141737\n",
      "Iteration 209, loss = 0.33918835\n",
      "Iteration 210, loss = 0.33696638\n",
      "Iteration 211, loss = 0.33475151\n",
      "Iteration 212, loss = 0.33254379\n",
      "Iteration 213, loss = 0.33034329\n",
      "Iteration 214, loss = 0.32815011\n",
      "Iteration 215, loss = 0.32596432\n",
      "Iteration 216, loss = 0.32378603\n",
      "Iteration 217, loss = 0.32161535\n",
      "Iteration 218, loss = 0.31945240\n",
      "Iteration 219, loss = 0.31729729\n",
      "Iteration 220, loss = 0.31515016\n",
      "Iteration 221, loss = 0.31301114\n",
      "Iteration 222, loss = 0.31088037\n",
      "Iteration 223, loss = 0.30875800\n",
      "Iteration 224, loss = 0.30664416\n",
      "Iteration 225, loss = 0.30453902\n",
      "Iteration 226, loss = 0.30244272\n",
      "Iteration 227, loss = 0.30035541\n",
      "Iteration 228, loss = 0.29827725\n",
      "Iteration 229, loss = 0.29620839\n",
      "Iteration 230, loss = 0.29414900\n",
      "Iteration 231, loss = 0.29209922\n",
      "Iteration 232, loss = 0.29005920\n",
      "Iteration 233, loss = 0.28802911\n",
      "Iteration 234, loss = 0.28600909\n",
      "Iteration 235, loss = 0.28399930\n",
      "Iteration 236, loss = 0.28199987\n",
      "Iteration 237, loss = 0.28001096\n",
      "Iteration 238, loss = 0.27803270\n",
      "Iteration 239, loss = 0.27606524\n",
      "Iteration 240, loss = 0.27410871\n",
      "Iteration 241, loss = 0.27216323\n",
      "Iteration 242, loss = 0.27022895\n",
      "Iteration 243, loss = 0.26830597\n",
      "Iteration 244, loss = 0.26639443\n",
      "Iteration 245, loss = 0.26449443\n",
      "Iteration 246, loss = 0.26260608\n",
      "Iteration 247, loss = 0.26072948\n",
      "Iteration 248, loss = 0.25886475\n",
      "Iteration 249, loss = 0.25701196\n",
      "Iteration 250, loss = 0.25517122\n",
      "Iteration 251, loss = 0.25334261\n",
      "Iteration 252, loss = 0.25152620\n",
      "Iteration 253, loss = 0.24972207\n",
      "Iteration 254, loss = 0.24793028\n",
      "Iteration 255, loss = 0.24615091\n",
      "Iteration 256, loss = 0.24438401\n",
      "Iteration 257, loss = 0.24262964\n",
      "Iteration 258, loss = 0.24088783\n",
      "Iteration 259, loss = 0.23915864\n",
      "Iteration 260, loss = 0.23744210\n",
      "Iteration 261, loss = 0.23573825\n",
      "Iteration 262, loss = 0.23404711\n",
      "Iteration 263, loss = 0.23236870\n",
      "Iteration 264, loss = 0.23070304\n",
      "Iteration 265, loss = 0.22905016\n",
      "Iteration 266, loss = 0.22741004\n",
      "Iteration 267, loss = 0.22578271\n",
      "Iteration 268, loss = 0.22416815\n",
      "Iteration 269, loss = 0.22256636\n",
      "Iteration 270, loss = 0.22097734\n",
      "Iteration 271, loss = 0.21940108\n",
      "Iteration 272, loss = 0.21783754\n",
      "Iteration 273, loss = 0.21628672\n",
      "Iteration 274, loss = 0.21474859\n",
      "Iteration 275, loss = 0.21322312\n",
      "Iteration 276, loss = 0.21171027\n",
      "Iteration 277, loss = 0.21021002\n",
      "Iteration 278, loss = 0.20872233\n",
      "Iteration 279, loss = 0.20724715\n",
      "Iteration 280, loss = 0.20578444\n",
      "Iteration 281, loss = 0.20433415\n",
      "Iteration 282, loss = 0.20289623\n",
      "Iteration 283, loss = 0.20147063\n",
      "Iteration 284, loss = 0.20005730\n",
      "Iteration 285, loss = 0.19865617\n",
      "Iteration 286, loss = 0.19726719\n",
      "Iteration 287, loss = 0.19589029\n",
      "Iteration 288, loss = 0.19452541\n",
      "Iteration 289, loss = 0.19317248\n",
      "Iteration 290, loss = 0.19183145\n",
      "Iteration 291, loss = 0.19050222\n",
      "Iteration 292, loss = 0.18918475\n",
      "Iteration 293, loss = 0.18787894\n",
      "Iteration 294, loss = 0.18658473\n",
      "Iteration 295, loss = 0.18530205\n",
      "Iteration 296, loss = 0.18403081\n",
      "Iteration 297, loss = 0.18277093\n",
      "Iteration 298, loss = 0.18152235\n",
      "Iteration 299, loss = 0.18028497\n",
      "Iteration 300, loss = 0.17905872\n",
      "Iteration 301, loss = 0.17784351\n",
      "Iteration 302, loss = 0.17663926\n",
      "Iteration 303, loss = 0.17544589\n",
      "Iteration 304, loss = 0.17426332\n",
      "Iteration 305, loss = 0.17309145\n",
      "Iteration 306, loss = 0.17193021\n",
      "Iteration 307, loss = 0.17077950\n",
      "Iteration 308, loss = 0.16963925\n",
      "Iteration 309, loss = 0.16850936\n",
      "Iteration 310, loss = 0.16738975\n",
      "Iteration 311, loss = 0.16628034\n",
      "Iteration 312, loss = 0.16518102\n",
      "Iteration 313, loss = 0.16409172\n",
      "Iteration 314, loss = 0.16301236\n",
      "Iteration 315, loss = 0.16194283\n",
      "Iteration 316, loss = 0.16088306\n",
      "Iteration 317, loss = 0.15983296\n",
      "Iteration 318, loss = 0.15879244\n",
      "Iteration 319, loss = 0.15776141\n",
      "Iteration 320, loss = 0.15673978\n",
      "Iteration 321, loss = 0.15572748\n",
      "Iteration 322, loss = 0.15472441\n",
      "Iteration 323, loss = 0.15373048\n",
      "Iteration 324, loss = 0.15274561\n",
      "Iteration 325, loss = 0.15176972\n",
      "Iteration 326, loss = 0.15080272\n",
      "Iteration 327, loss = 0.14984452\n",
      "Iteration 328, loss = 0.14889503\n",
      "Iteration 329, loss = 0.14795418\n",
      "Iteration 330, loss = 0.14702189\n",
      "Iteration 331, loss = 0.14609805\n",
      "Iteration 332, loss = 0.14518261\n",
      "Iteration 333, loss = 0.14427546\n",
      "Iteration 334, loss = 0.14337653\n",
      "Iteration 335, loss = 0.14248574\n",
      "Iteration 336, loss = 0.14160300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 337, loss = 0.14072824\n",
      "Iteration 338, loss = 0.13986137\n",
      "Iteration 339, loss = 0.13900233\n",
      "Iteration 340, loss = 0.13815101\n",
      "Iteration 341, loss = 0.13730736\n",
      "Iteration 342, loss = 0.13647129\n",
      "Iteration 343, loss = 0.13564272\n",
      "Iteration 344, loss = 0.13482158\n",
      "Iteration 345, loss = 0.13400779\n",
      "Iteration 346, loss = 0.13320127\n",
      "Iteration 347, loss = 0.13240196\n",
      "Iteration 348, loss = 0.13160977\n",
      "Iteration 349, loss = 0.13082464\n",
      "Iteration 350, loss = 0.13004649\n",
      "Iteration 351, loss = 0.12927524\n",
      "Iteration 352, loss = 0.12851084\n",
      "Iteration 353, loss = 0.12775320\n",
      "Iteration 354, loss = 0.12700225\n",
      "Iteration 355, loss = 0.12625793\n",
      "Iteration 356, loss = 0.12552017\n",
      "Iteration 357, loss = 0.12478890\n",
      "Iteration 358, loss = 0.12406405\n",
      "Iteration 359, loss = 0.12334556\n",
      "Iteration 360, loss = 0.12263335\n",
      "Iteration 361, loss = 0.12192736\n",
      "Iteration 362, loss = 0.12122754\n",
      "Iteration 363, loss = 0.12053380\n",
      "Iteration 364, loss = 0.11984610\n",
      "Iteration 365, loss = 0.11916435\n",
      "Iteration 366, loss = 0.11848852\n",
      "Iteration 367, loss = 0.11781852\n",
      "Iteration 368, loss = 0.11715431\n",
      "Iteration 369, loss = 0.11649581\n",
      "Iteration 370, loss = 0.11584298\n",
      "Iteration 371, loss = 0.11519574\n",
      "Iteration 372, loss = 0.11455405\n",
      "Iteration 373, loss = 0.11391784\n",
      "Iteration 374, loss = 0.11328705\n",
      "Iteration 375, loss = 0.11266164\n",
      "Iteration 376, loss = 0.11204153\n",
      "Iteration 377, loss = 0.11142669\n",
      "Iteration 378, loss = 0.11081705\n",
      "Iteration 379, loss = 0.11021255\n",
      "Iteration 380, loss = 0.10961315\n",
      "Iteration 381, loss = 0.10901879\n",
      "Iteration 382, loss = 0.10842942\n",
      "Iteration 383, loss = 0.10784498\n",
      "Iteration 384, loss = 0.10726543\n",
      "Iteration 385, loss = 0.10669071\n",
      "Iteration 386, loss = 0.10612077\n",
      "Iteration 387, loss = 0.10555557\n",
      "Iteration 388, loss = 0.10499505\n",
      "Iteration 389, loss = 0.10443916\n",
      "Iteration 390, loss = 0.10388787\n",
      "Iteration 391, loss = 0.10334111\n",
      "Iteration 392, loss = 0.10279884\n",
      "Iteration 393, loss = 0.10226102\n",
      "Iteration 394, loss = 0.10172759\n",
      "Iteration 395, loss = 0.10119852\n",
      "Iteration 396, loss = 0.10067376\n",
      "Iteration 397, loss = 0.10015327\n",
      "Iteration 398, loss = 0.09963699\n",
      "Iteration 399, loss = 0.09912489\n",
      "Iteration 400, loss = 0.09861692\n",
      "Iteration 401, loss = 0.09811304\n",
      "Iteration 402, loss = 0.09761321\n",
      "Iteration 403, loss = 0.09711739\n",
      "Iteration 404, loss = 0.09662554\n",
      "Iteration 405, loss = 0.09613761\n",
      "Iteration 406, loss = 0.09565356\n",
      "Iteration 407, loss = 0.09517336\n",
      "Iteration 408, loss = 0.09469697\n",
      "Iteration 409, loss = 0.09422434\n",
      "Iteration 410, loss = 0.09375544\n",
      "Iteration 411, loss = 0.09329023\n",
      "Iteration 412, loss = 0.09282868\n",
      "Iteration 413, loss = 0.09237074\n",
      "Iteration 414, loss = 0.09191638\n",
      "Iteration 415, loss = 0.09146557\n",
      "Iteration 416, loss = 0.09101826\n",
      "Iteration 417, loss = 0.09057442\n",
      "Iteration 418, loss = 0.09013402\n",
      "Iteration 419, loss = 0.08969703\n",
      "Iteration 420, loss = 0.08926340\n",
      "Iteration 421, loss = 0.08883310\n",
      "Iteration 422, loss = 0.08840611\n",
      "Iteration 423, loss = 0.08798238\n",
      "Iteration 424, loss = 0.08756189\n",
      "Iteration 425, loss = 0.08714460\n",
      "Iteration 426, loss = 0.08673049\n",
      "Iteration 427, loss = 0.08631951\n",
      "Iteration 428, loss = 0.08591164\n",
      "Iteration 429, loss = 0.08550684\n",
      "Iteration 430, loss = 0.08510509\n",
      "Iteration 431, loss = 0.08470636\n",
      "Iteration 432, loss = 0.08431062\n",
      "Iteration 433, loss = 0.08391783\n",
      "Iteration 434, loss = 0.08352797\n",
      "Iteration 435, loss = 0.08314101\n",
      "Iteration 436, loss = 0.08275692\n",
      "Iteration 437, loss = 0.08237568\n",
      "Iteration 438, loss = 0.08199725\n",
      "Iteration 439, loss = 0.08162160\n",
      "Iteration 440, loss = 0.08124872\n",
      "Iteration 441, loss = 0.08087856\n",
      "Iteration 442, loss = 0.08051112\n",
      "Iteration 443, loss = 0.08014635\n",
      "Iteration 444, loss = 0.07978424\n",
      "Iteration 445, loss = 0.07942476\n",
      "Iteration 446, loss = 0.07906788\n",
      "Iteration 447, loss = 0.07871358\n",
      "Iteration 448, loss = 0.07836183\n",
      "Iteration 449, loss = 0.07801261\n",
      "Iteration 450, loss = 0.07766589\n",
      "Iteration 451, loss = 0.07732166\n",
      "Iteration 452, loss = 0.07697988\n",
      "Iteration 453, loss = 0.07664053\n",
      "Iteration 454, loss = 0.07630359\n",
      "Iteration 455, loss = 0.07596904\n",
      "Iteration 456, loss = 0.07563686\n",
      "Iteration 457, loss = 0.07530702\n",
      "Iteration 458, loss = 0.07497949\n",
      "Iteration 459, loss = 0.07465427\n",
      "Iteration 460, loss = 0.07433132\n",
      "Iteration 461, loss = 0.07401062\n",
      "Iteration 462, loss = 0.07369216\n",
      "Iteration 463, loss = 0.07337591\n",
      "Iteration 464, loss = 0.07306186\n",
      "Iteration 465, loss = 0.07274997\n",
      "Iteration 466, loss = 0.07244024\n",
      "Iteration 467, loss = 0.07213263\n",
      "Iteration 468, loss = 0.07182714\n",
      "Iteration 469, loss = 0.07152374\n",
      "Iteration 470, loss = 0.07122241\n",
      "Iteration 471, loss = 0.07092314\n",
      "Iteration 472, loss = 0.07062590\n",
      "Iteration 473, loss = 0.07033067\n",
      "Iteration 474, loss = 0.07003744\n",
      "Iteration 475, loss = 0.06974620\n",
      "Iteration 476, loss = 0.06945691\n",
      "Iteration 477, loss = 0.06916956\n",
      "Iteration 478, loss = 0.06888414\n",
      "Iteration 479, loss = 0.06860063\n",
      "Iteration 480, loss = 0.06831900\n",
      "Iteration 481, loss = 0.06803925\n",
      "Iteration 482, loss = 0.06776136\n",
      "Iteration 483, loss = 0.06748530\n",
      "Iteration 484, loss = 0.06721107\n",
      "Iteration 485, loss = 0.06693865\n",
      "Iteration 486, loss = 0.06666801\n",
      "Iteration 487, loss = 0.06639915\n",
      "Iteration 488, loss = 0.06613205\n",
      "Iteration 489, loss = 0.06586669\n",
      "Iteration 490, loss = 0.06560305\n",
      "Iteration 491, loss = 0.06534113\n",
      "Iteration 492, loss = 0.06508091\n",
      "Iteration 493, loss = 0.06482237\n",
      "Iteration 494, loss = 0.06456549\n",
      "Iteration 495, loss = 0.06431027\n",
      "Iteration 496, loss = 0.06405668\n",
      "Iteration 497, loss = 0.06380472\n",
      "Iteration 498, loss = 0.06355437\n",
      "Iteration 499, loss = 0.06330561\n",
      "Iteration 500, loss = 0.06305844\n",
      "Iteration 501, loss = 0.06281283\n",
      "Iteration 502, loss = 0.06256877\n",
      "Iteration 503, loss = 0.06232626\n",
      "Iteration 504, loss = 0.06208527\n",
      "Iteration 505, loss = 0.06184580\n",
      "Iteration 506, loss = 0.06160783\n",
      "Iteration 507, loss = 0.06137135\n",
      "Iteration 508, loss = 0.06113634\n",
      "Iteration 509, loss = 0.06090279\n",
      "Iteration 510, loss = 0.06067070\n",
      "Iteration 511, loss = 0.06044005\n",
      "Iteration 512, loss = 0.06021082\n",
      "Iteration 513, loss = 0.05998300\n",
      "Iteration 514, loss = 0.05975659\n",
      "Iteration 515, loss = 0.05953156\n",
      "Iteration 516, loss = 0.05930792\n",
      "Iteration 517, loss = 0.05908564\n",
      "Iteration 518, loss = 0.05886472\n",
      "Iteration 519, loss = 0.05864514\n",
      "Iteration 520, loss = 0.05842689\n",
      "Iteration 521, loss = 0.05820997\n",
      "Iteration 522, loss = 0.05799436\n",
      "Iteration 523, loss = 0.05778005\n",
      "Iteration 524, loss = 0.05756703\n",
      "Iteration 525, loss = 0.05735528\n",
      "Iteration 526, loss = 0.05714481\n",
      "Iteration 527, loss = 0.05693559\n",
      "Iteration 528, loss = 0.05672762\n",
      "Iteration 529, loss = 0.05652089\n",
      "Iteration 530, loss = 0.05631539\n",
      "Iteration 531, loss = 0.05611110\n",
      "Iteration 532, loss = 0.05590802\n",
      "Iteration 533, loss = 0.05570614\n",
      "Iteration 534, loss = 0.05550545\n",
      "Iteration 535, loss = 0.05530594\n",
      "Iteration 536, loss = 0.05510759\n",
      "Iteration 537, loss = 0.05491041\n",
      "Iteration 538, loss = 0.05471438\n",
      "Iteration 539, loss = 0.05451949\n",
      "Iteration 540, loss = 0.05432573\n",
      "Iteration 541, loss = 0.05413309\n",
      "Iteration 542, loss = 0.05394157\n",
      "Iteration 543, loss = 0.05375116\n",
      "Iteration 544, loss = 0.05356184\n",
      "Iteration 545, loss = 0.05337361\n",
      "Iteration 546, loss = 0.05318646\n",
      "Iteration 547, loss = 0.05300038\n",
      "Iteration 548, loss = 0.05281536\n",
      "Iteration 549, loss = 0.05263140\n",
      "Iteration 550, loss = 0.05244849\n",
      "Iteration 551, loss = 0.05226662\n",
      "Iteration 552, loss = 0.05208577\n",
      "Iteration 553, loss = 0.05190595\n",
      "Iteration 554, loss = 0.05172714\n",
      "Iteration 555, loss = 0.05154934\n",
      "Iteration 556, loss = 0.05137254\n",
      "Iteration 557, loss = 0.05119673\n",
      "Iteration 558, loss = 0.05102191\n",
      "Iteration 559, loss = 0.05084806\n",
      "Iteration 560, loss = 0.05067518\n",
      "Iteration 561, loss = 0.05050326\n",
      "Iteration 562, loss = 0.05033230\n",
      "Iteration 563, loss = 0.05016228\n",
      "Iteration 564, loss = 0.04999320\n",
      "Iteration 565, loss = 0.04982506\n",
      "Iteration 566, loss = 0.04965784\n",
      "Iteration 567, loss = 0.04949154\n",
      "Iteration 568, loss = 0.04932615\n",
      "Iteration 569, loss = 0.04916167\n",
      "Iteration 570, loss = 0.04899809\n",
      "Iteration 571, loss = 0.04883540\n",
      "Iteration 572, loss = 0.04867359\n",
      "Iteration 573, loss = 0.04851267\n",
      "Iteration 574, loss = 0.04835261\n",
      "Iteration 575, loss = 0.04819342\n",
      "Iteration 576, loss = 0.04803509\n",
      "Iteration 577, loss = 0.04787761\n",
      "Iteration 578, loss = 0.04772098\n",
      "Iteration 579, loss = 0.04756520\n",
      "Iteration 580, loss = 0.04741024\n",
      "Iteration 581, loss = 0.04725611\n",
      "Iteration 582, loss = 0.04710281\n",
      "Iteration 583, loss = 0.04695032\n",
      "Iteration 584, loss = 0.04679864\n",
      "Iteration 585, loss = 0.04664777\n",
      "Iteration 586, loss = 0.04649770\n",
      "Iteration 587, loss = 0.04634842\n",
      "Iteration 588, loss = 0.04619992\n",
      "Iteration 589, loss = 0.04605221\n",
      "Iteration 590, loss = 0.04590527\n",
      "Iteration 591, loss = 0.04575911\n",
      "Iteration 592, loss = 0.04561371\n",
      "Iteration 593, loss = 0.04546907\n",
      "Iteration 594, loss = 0.04532518\n",
      "Iteration 595, loss = 0.04518204\n",
      "Iteration 596, loss = 0.04503964\n",
      "Iteration 597, loss = 0.04489799\n",
      "Iteration 598, loss = 0.04475706\n",
      "Iteration 599, loss = 0.04461687\n",
      "Iteration 600, loss = 0.04447739\n",
      "Iteration 601, loss = 0.04433864\n",
      "Iteration 602, loss = 0.04420059\n",
      "Iteration 603, loss = 0.04406325\n",
      "Iteration 604, loss = 0.04392662\n",
      "Iteration 605, loss = 0.04379068\n",
      "Iteration 606, loss = 0.04365544\n",
      "Iteration 607, loss = 0.04352088\n",
      "Iteration 608, loss = 0.04338701\n",
      "Iteration 609, loss = 0.04325381\n",
      "Iteration 610, loss = 0.04312129\n",
      "Iteration 611, loss = 0.04298944\n",
      "Iteration 612, loss = 0.04285825\n",
      "Iteration 613, loss = 0.04272772\n",
      "Iteration 614, loss = 0.04259785\n",
      "Iteration 615, loss = 0.04246862\n",
      "Iteration 616, loss = 0.04234005\n",
      "Iteration 617, loss = 0.04221211\n",
      "Iteration 618, loss = 0.04208481\n",
      "Iteration 619, loss = 0.04195815\n",
      "Iteration 620, loss = 0.04183211\n",
      "Iteration 621, loss = 0.04170670\n",
      "Iteration 622, loss = 0.04158191\n",
      "Iteration 623, loss = 0.04145773\n",
      "Iteration 624, loss = 0.04133416\n",
      "Iteration 625, loss = 0.04121121\n",
      "Iteration 626, loss = 0.04108885\n",
      "Iteration 627, loss = 0.04096710\n",
      "Iteration 628, loss = 0.04084594\n",
      "Iteration 629, loss = 0.04072537\n",
      "Iteration 630, loss = 0.04060539\n",
      "Iteration 631, loss = 0.04048599\n",
      "Iteration 632, loss = 0.04036718\n",
      "Iteration 633, loss = 0.04024893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 634, loss = 0.04013126\n",
      "Iteration 635, loss = 0.04001416\n",
      "Iteration 636, loss = 0.03989762\n",
      "Iteration 637, loss = 0.03978164\n",
      "Iteration 638, loss = 0.03966622\n",
      "Iteration 639, loss = 0.03955135\n",
      "Iteration 640, loss = 0.03943703\n",
      "Iteration 641, loss = 0.03932326\n",
      "Iteration 642, loss = 0.03921003\n",
      "Iteration 643, loss = 0.03909734\n",
      "Iteration 644, loss = 0.03898518\n",
      "Iteration 645, loss = 0.03887355\n",
      "Iteration 646, loss = 0.03876245\n",
      "Iteration 647, loss = 0.03865188\n",
      "Iteration 648, loss = 0.03854182\n",
      "Iteration 649, loss = 0.03843229\n",
      "Iteration 650, loss = 0.03832327\n",
      "Iteration 651, loss = 0.03821476\n",
      "Iteration 652, loss = 0.03810675\n",
      "Iteration 653, loss = 0.03799925\n",
      "Iteration 654, loss = 0.03789226\n",
      "Iteration 655, loss = 0.03778576\n",
      "Iteration 656, loss = 0.03767975\n",
      "Iteration 657, loss = 0.03757424\n",
      "Iteration 658, loss = 0.03746921\n",
      "Iteration 659, loss = 0.03736467\n",
      "Iteration 660, loss = 0.03726061\n",
      "Iteration 661, loss = 0.03715704\n",
      "Iteration 662, loss = 0.03705393\n",
      "Iteration 663, loss = 0.03695130\n",
      "Iteration 664, loss = 0.03684914\n",
      "Iteration 665, loss = 0.03674745\n",
      "Iteration 666, loss = 0.03664622\n",
      "Iteration 667, loss = 0.03654545\n",
      "Iteration 668, loss = 0.03644514\n",
      "Iteration 669, loss = 0.03634528\n",
      "Iteration 670, loss = 0.03624588\n",
      "Iteration 671, loss = 0.03614692\n",
      "Iteration 672, loss = 0.03604842\n",
      "Iteration 673, loss = 0.03595035\n",
      "Iteration 674, loss = 0.03585273\n",
      "Iteration 675, loss = 0.03575554\n",
      "Iteration 676, loss = 0.03565879\n",
      "Iteration 677, loss = 0.03556248\n",
      "Iteration 678, loss = 0.03546659\n",
      "Iteration 679, loss = 0.03537113\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(30, 30), max_iter=1000,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#activation = \"identity\"\n",
    "activation = \"logistic\"\n",
    "#activation = \"tanh\"\n",
    "#activation = \"relu\"\n",
    "mlp = MLPClassifier(#random_state=42,\n",
    "                    hidden_layer_sizes=(30,30),\n",
    "                    max_iter = 1000,\n",
    "                    activation = activation,\n",
    "                    verbose = True\n",
    "                    )\n",
    "mlp.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de iteraciones: 679\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Cantidad de iteraciones: \" +str(mlp.n_iter_))\n",
    "disp = metrics.plot_confusion_matrix(mlp, X_test, y_test,cmap=plt.cm.Blues)\n",
    "disp.ax_.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
